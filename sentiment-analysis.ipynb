{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92643bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vaishalee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vaishalee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vaishalee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5201ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = pd.DataFrame(pd.read_excel('Input.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e5788f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418ab4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file=pd.DataFrame()\n",
    "output_file['URL_ID']=input_files['URL_ID']\n",
    "output_file['URL']=input_files['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Code for content scraping from URLs\n",
    "def content_scraping(x):\n",
    "  url = x\n",
    "  reqs = requests.get(url)\n",
    "  soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "  title=soup.find('title').get_text()\n",
    "\n",
    "  content=soup.find(\"div\", {\"class\": \"td-post-content tagdiv-type\"})\n",
    "  if content is not None:\n",
    "    content=content.get_text()\n",
    "\n",
    "  if content is None:\n",
    "    content=soup.find_all(\"div\", class_=\"tdb-block-inner td-fix-index\")\n",
    "    max_val=-1\n",
    "    flag=-1\n",
    "    numb=-1\n",
    "\n",
    "    for i in content:\n",
    "      numb=numb+1\n",
    "      temp_con=i.get_text()\n",
    "      if max_val<len(temp_con):\n",
    "        max_val=len(temp_con)\n",
    "        flag=numb\n",
    "\n",
    "    content=content[flag].get_text()\n",
    "\n",
    "  content=title+\"\\n\"+content\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e09bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "all_content=[]\n",
    "for ind in input_files['URL'].index:\n",
    "  print(ind)\n",
    "  curr_content=content_scraping(input_files['URL'][ind])\n",
    "  all_content.append(curr_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35586124",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['Data']=all_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6462a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Code to Create txt files of the web scraped content with filename as the URL ID\n",
    "# for ind in output_file.index:\n",
    "#   filename=base_location+output_file['URL_ID'][ind]+'.txt'\n",
    "#   f = open(filename, \"w\")\n",
    "#   f.write(output_file['Data'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7ab57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading the stopwords given in the project folder\n",
    "file_list = glob.glob('StopWords/*.txt')\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        \n",
    "        stopwords.extend(f.read().lower().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e006e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words= []\n",
    "with open('MasterDictionary/positive-words.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "  pos_words.extend(f.read().lower().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498cc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words= []\n",
    "with open('MasterDictionary/negative-words.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "  neg_words.extend(f.read().lower().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49109889",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Preprocessing the text by changing it to lower case, removing all punctuation,\n",
    "##### tokenizing it and removing the stopwords and saving it to a column in\n",
    "##### dataframe for further use\n",
    "def text_prep(x):\n",
    "    corp = str(x).lower()\n",
    "    corp = re.sub('[^a-zA-Z]+', ' ', corp).strip()\n",
    "    tokens = word_tokenize(corp)\n",
    "    words = [t for t in tokens if t not in stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ceb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['Processed']= output_file['Data'].apply(text_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2520c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining functions to calculate positive, nagative and polarity score\n",
    "def positive(words):\n",
    "    pos_count=len([i for i in words if i in pos_words])\n",
    "    return pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9623b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(words):\n",
    "    neg_count=len([i for i in words if i in neg_words])\n",
    "    return neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a2b30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(positive, negative):\n",
    "  pol_score=(positive-negative)/(positive+negative+0.000001)\n",
    "  return pol_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bbfe51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Using the defined functions to calculate the positive, negative and polarity\n",
    "##### score and storing it in columns in the dataframe\n",
    "output_file['POSITIVE SCORE']= output_file['Processed'].apply(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79ca2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['NEGATIVE SCORE']= output_file['Processed'].apply(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50ad44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['POLARITY SCORE']= output_file.apply(lambda row: polarity(row['POSITIVE SCORE'], row['NEGATIVE SCORE']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d3e02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining function to calculate subjectivity score and saving it in dataframe\n",
    "def subjectivity(positive, negative, cleaned_words_number):\n",
    "  sub_score=(positive+negative)/(cleaned_words_number+0.000001)\n",
    "  return sub_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd8dc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['SUBJECTIVITY SCORE']= output_file.apply(lambda row: subjectivity(row['POSITIVE SCORE'], row['NEGATIVE SCORE'], len(row['Processed'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "849d4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining function to calculate average sentence length and saving it in\n",
    "##### dataframe\n",
    "def avg_sentence_len(content, words):\n",
    "  sentences = sent_tokenize(content)\n",
    "  total_sent = len(sentences)\n",
    "  total_words = len(words)\n",
    "  avg_sentence_length = total_words / total_sent if total_sent > 0 else 0\n",
    "  return avg_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f89b2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['AVG SENTENCE LENGTH']= output_file.apply(lambda row: avg_sentence_len(row['Data'], row['Processed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c2620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function to calculate the number of syllables in a given word according to\n",
    "##### accepted rules of the english language\n",
    "def sylco(word) :\n",
    "    word = word.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"\n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" :\n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass\n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1\n",
    "\n",
    "    # calculate the output\n",
    "    return numVowels - disc + syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f18abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate percentage of complex words and saving\n",
    "##### it in the dataframe\n",
    "def percent_complex(words):\n",
    "\n",
    "  complex_words = [word for word in words if sylco(word) > 2]\n",
    "\n",
    "  total_words = len(words)\n",
    "  total_complex_words = len(complex_words)\n",
    "\n",
    "  percentage_complex_words = (total_complex_words / total_words)*100 if total_words > 0 else 0\n",
    "  return percentage_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25639b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['PERCENTAGE OF COMPLEX WORDS']= output_file.apply(lambda row: percent_complex(row['Processed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48325c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate fog index and saving it in dataframe\n",
    "def fog(avg_sent_len, percentage_complex):\n",
    "  fog_index = 0.4*(avg_sent_len + percentage_complex)\n",
    "  return fog_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bdf3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['FOG INDEX']= output_file.apply(lambda row: fog(row['AVG SENTENCE LENGTH'], row['PERCENTAGE OF COMPLEX WORDS']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38836d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving the average number of words per sentence in dataframe\n",
    "output_file['AVG NUMBER OF WORDS PER SENTENCE']=output_file['AVG SENTENCE LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30f81019",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate number of complex words and saving it in\n",
    "##### dataframe\n",
    "def no_complex(words):\n",
    "  complex_words = [word for word in words if sylco(word) > 2]\n",
    "  total_complex_words = len(complex_words)\n",
    "\n",
    "  return total_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e8e924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['COMPLEX WORD COUNT']= output_file.apply(lambda row: no_complex(row['Processed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f72fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to clean the text by removing puntuation, tokenizing\n",
    "##### it and removing stopwords defined in the nltk library. The function\n",
    "##### returns the number of clean words after performing the above operations\n",
    "def text_clean(content):\n",
    "  corp = re.sub('[^a-zA-Z]+', ' ', content).strip()\n",
    "  tokens = word_tokenize(corp)\n",
    "  words = [t for t in tokens if t not in stopwords]\n",
    "  return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f0184bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving the clean words count using the above function\n",
    "output_file['WORD COUNT']= output_file.apply(lambda row: text_clean(row['Data']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52832c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate the average number of syllables per word\n",
    "##### and saving it in dataframe\n",
    "def syllable_per_word(words):\n",
    "  no_of_syllables=0\n",
    "  for word in words:\n",
    "    no_of_syllables=no_of_syllables+sylco(word)\n",
    "  avg_syllables=no_of_syllables/len(words) if len(words)>0 else 0\n",
    "  return avg_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e302003",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['SYLLABLE PER WORD']= output_file.apply(lambda row: syllable_per_word(row['Processed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4e81bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate the number of personal pronouns and\n",
    "##### saving it in dataframe\n",
    "def cal_personal_pronouns(content):\n",
    "  pronoun_re = r'\\b(I|my|My|we|We|us|Us|ours|Ours)\\b'\n",
    "  matches = re.findall(pronoun_re, content)\n",
    "  return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8266fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['PERSONAL PRONOUNS']= output_file.apply(lambda row: cal_personal_pronouns(row['Data']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfcb8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Defining a function to calculate the average word length and saving it in\n",
    "##### dataframe\n",
    "def avg_word_length(words):\n",
    "  no_of_characters=0\n",
    "  for word in words:\n",
    "    no_of_characters=no_of_characters+len(word)\n",
    "  avg_word_len=no_of_characters/len(words)\n",
    "  return avg_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4e2b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file['AVG WORD LENGTH']= output_file.apply(lambda row: avg_word_length(row['Processed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ae52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Data</th>\n",
       "      <th>Processed</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>Rising IT cities and its impact on the economy...</td>\n",
       "      <td>[rising, cities, impact, economy, environment,...</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>6.151899</td>\n",
       "      <td>31.893004</td>\n",
       "      <td>15.217961</td>\n",
       "      <td>6.151899</td>\n",
       "      <td>155</td>\n",
       "      <td>608</td>\n",
       "      <td>2.257202</td>\n",
       "      <td>11</td>\n",
       "      <td>6.915638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>Rising IT Cities and Their Impact on the Econo...</td>\n",
       "      <td>[rising, cities, impact, economy, environment,...</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>44.428152</td>\n",
       "      <td>21.181261</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>303</td>\n",
       "      <td>772</td>\n",
       "      <td>2.565982</td>\n",
       "      <td>4</td>\n",
       "      <td>7.768328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>Internet Demand's Evolution, Communication Imp...</td>\n",
       "      <td>[internet, demand, evolution, communication, i...</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>10.771930</td>\n",
       "      <td>51.465798</td>\n",
       "      <td>24.895091</td>\n",
       "      <td>10.771930</td>\n",
       "      <td>316</td>\n",
       "      <td>666</td>\n",
       "      <td>2.741042</td>\n",
       "      <td>13</td>\n",
       "      <td>8.276873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>Rise of Cybercrime and its Effect in upcoming ...</td>\n",
       "      <td>[rise, cybercrime, effect, upcoming, future, b...</td>\n",
       "      <td>35</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.357798</td>\n",
       "      <td>0.185374</td>\n",
       "      <td>11.307692</td>\n",
       "      <td>50.680272</td>\n",
       "      <td>24.795186</td>\n",
       "      <td>11.307692</td>\n",
       "      <td>298</td>\n",
       "      <td>623</td>\n",
       "      <td>2.693878</td>\n",
       "      <td>5</td>\n",
       "      <td>8.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>OTT platform and its impact on the entertainme...</td>\n",
       "      <td>[platform, impact, entertainment, industry, fu...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>36.337209</td>\n",
       "      <td>17.974884</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>125</td>\n",
       "      <td>395</td>\n",
       "      <td>2.360465</td>\n",
       "      <td>6</td>\n",
       "      <td>7.764535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "\n",
       "                                                Data  \\\n",
       "0  Rising IT cities and its impact on the economy...   \n",
       "1  Rising IT Cities and Their Impact on the Econo...   \n",
       "2  Internet Demand's Evolution, Communication Imp...   \n",
       "3  Rise of Cybercrime and its Effect in upcoming ...   \n",
       "4  OTT platform and its impact on the entertainme...   \n",
       "\n",
       "                                           Processed  POSITIVE SCORE  \\\n",
       "0  [rising, cities, impact, economy, environment,...              27   \n",
       "1  [rising, cities, impact, economy, environment,...              52   \n",
       "2  [internet, demand, evolution, communication, i...              36   \n",
       "3  [rise, cybercrime, effect, upcoming, future, b...              35   \n",
       "4  [platform, impact, entertainment, industry, fu...              23   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               6        0.636364            0.067901             6.151899   \n",
       "1              31        0.253012            0.121701             8.525000   \n",
       "2              25        0.180328            0.099349            10.771930   \n",
       "3              74       -0.357798            0.185374            11.307692   \n",
       "4               9        0.437500            0.093023             8.600000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    31.893004  15.217961                          6.151899   \n",
       "1                    44.428152  21.181261                          8.525000   \n",
       "2                    51.465798  24.895091                         10.771930   \n",
       "3                    50.680272  24.795186                         11.307692   \n",
       "4                    36.337209  17.974884                          8.600000   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 155         608           2.257202                 11   \n",
       "1                 303         772           2.565982                  4   \n",
       "2                 316         666           2.741042                 13   \n",
       "3                 298         623           2.693878                  5   \n",
       "4                 125         395           2.360465                  6   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         6.915638  \n",
       "1         7.768328  \n",
       "2         8.276873  \n",
       "3         8.204082  \n",
       "4         7.764535  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Printing the first five rows of dataframe\n",
    "output_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f05e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Dropping the columns containing web scraped data anf processed data and\n",
    "##### saving the dataframe as a csv file\n",
    "output_file.drop(['Data', 'Processed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9eaa2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.to_csv('output_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75acf994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
